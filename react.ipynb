{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "639d7f41",
   "metadata": {},
   "source": [
    "# ReAct agent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7b4b544",
   "metadata": {},
   "source": [
    "**Autores:** [Lucas Lima](https://github.com/lucasouzamil) e [Luiz Eduardo Pini](https://github.com/luizehp)\n",
    "\n",
    "**Vídeo de explicação:** [YouTube](https://youtu.be/awaqm7JQ99g)\n",
    "\n",
    "**Baseado no artigo** [Multi-agent System Design Patterns From Scratch In Python | ReAct Agents](https://medium.com/aimonks/multi-agent-system-design-patterns-from-scratch-in-python-react-agents-e4480d099f38)\n",
    "\n",
    "**Nossas modificações:** Alteramos para usar o modelo do Gemini e também alteramos o prompt original para aceitar o scratchpad no final. Dessa forma o agente pode funcionar em sessões diferentes, ao invés de permanecer em uma única."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "afb63d69",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Callable, Dict, Any\n",
    "import json\n",
    "\n",
    "def extract_function_metadata(function: Callable) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Creates a metadata dictionary from a function's signature.\n",
    "    \n",
    "    Parameters:\n",
    "        function: The target function to analyze\n",
    "        \n",
    "    Returns:\n",
    "        A dictionary containing the function's name, documentation, and parameter specifications\n",
    "    \"\"\"\n",
    "    # Initialize the basic structure\n",
    "    metadata = {\n",
    "        \"name\": function.__name__,\n",
    "        \"description\": function.__doc__,\n",
    "        \"parameters\": {\"properties\": {}}\n",
    "    }\n",
    "    \n",
    "    # Extract parameter types (excluding return annotation)\n",
    "    parameter_types = {\n",
    "        param_name: {\"type\": param_type.__name__}\n",
    "        for param_name, param_type in function.__annotations__.items()\n",
    "        if param_name != \"return\"\n",
    "    }\n",
    "    \n",
    "    # Add parameters to metadata\n",
    "    metadata[\"parameters\"][\"properties\"] = parameter_types\n",
    "    return metadata\n",
    "\n",
    "def convert_argument_types(tool_invocation: Dict[str, Any], function_spec: Dict[str, Any]) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Ensures all arguments match their expected types according to the function specification.\n",
    "    \n",
    "    Parameters:\n",
    "        tool_invocation: Dictionary with the tool name and arguments\n",
    "        function_spec: Dictionary containing the expected parameter types\n",
    "        \n",
    "    Returns:\n",
    "        Updated tool invocation with correctly typed arguments\n",
    "    \"\"\"\n",
    "    expected_params = function_spec[\"parameters\"][\"properties\"]\n",
    "    \n",
    "    # Type conversion mapping\n",
    "    type_converters = {\n",
    "        \"int\": int,\n",
    "        \"str\": str,\n",
    "        \"bool\": bool,\n",
    "        \"float\": float\n",
    "    }\n",
    "    \n",
    "    # Convert each argument to its expected type if needed\n",
    "    for arg_name, arg_value in tool_invocation[\"arguments\"].items():\n",
    "        target_type = expected_params[arg_name].get(\"type\")\n",
    "        if not isinstance(arg_value, type_converters[target_type]):\n",
    "            tool_invocation[\"arguments\"][arg_name] = type_converters[target_type](arg_value)\n",
    "            \n",
    "    return tool_invocation\n",
    "\n",
    "class Tool:\n",
    "    \"\"\"\n",
    "    Wrapper class that encapsulates a function as a callable tool.\n",
    "    \n",
    "    Attributes:\n",
    "        name: Tool identifier\n",
    "        function: The underlying function\n",
    "        specification: JSON-formatted function metadata\n",
    "    \"\"\"\n",
    "    def __init__(self, name: str, function: Callable, specification: str):\n",
    "        self.name = name\n",
    "        self.function = function\n",
    "        self.specification = specification\n",
    "        \n",
    "    def __str__(self):\n",
    "        return self.specification\n",
    "        \n",
    "    def execute(self, **kwargs):\n",
    "        \"\"\"\n",
    "        Runs the wrapped function with the provided arguments.\n",
    "        \n",
    "        Parameters:\n",
    "            **kwargs: Arguments to pass to the function\n",
    "            \n",
    "        Returns:\n",
    "            The function's result\n",
    "        \"\"\"\n",
    "        return self.function(**kwargs)\n",
    "\n",
    "def tool(function: Callable) -> Tool:\n",
    "    \"\"\"\n",
    "    Decorator that transforms a regular function into a Tool instance.\n",
    "    \n",
    "    Parameters:\n",
    "        function: The function to convert into a tool\n",
    "        \n",
    "    Returns:\n",
    "        A fully configured Tool object\n",
    "    \"\"\"\n",
    "    def create_tool():\n",
    "        metadata = extract_function_metadata(function)\n",
    "        return Tool(\n",
    "            name=metadata.get(\"name\"),\n",
    "            function=function,\n",
    "            specification=json.dumps(metadata)\n",
    "        )\n",
    "    \n",
    "    return create_tool()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "7dff5204",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import re\n",
    "from typing import List, Dict, Any, Callable\n",
    "from colorama import init, Fore, Style\n",
    "\n",
    "# Initialize colorama\n",
    "init(autoreset=True)\n",
    "\n",
    "class ToolCallingAgent:\n",
    "    \"\"\"\n",
    "    An agent that integrates language models with function-calling tools.\n",
    "    \n",
    "    This class manages the interaction between a language model and a set of tools,\n",
    "    allowing the model to decide when to call functions and processing the results.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, llm: Callable, system_prompt: str, tools: List[Any]):\n",
    "        \"\"\"\n",
    "        Initialize an AI agent with a language model and tools.\n",
    "        \n",
    "        Args:\n",
    "            llm: Function that takes a prompt string and returns a response\n",
    "            system_prompt: Instructions for guiding the language model's behavior\n",
    "            tools: List of Tool objects that the agent can use\n",
    "        \"\"\"\n",
    "        self.model = llm\n",
    "        self.system_prompt = system_prompt\n",
    "        self.tools = {tool.name: tool for tool in tools}\n",
    "        self.conversation_history = []\n",
    "        print(f\"{Fore.GREEN}ToolCallingAgent initialized with {len(tools)} tools{Style.RESET_ALL}\")\n",
    "        \n",
    "    def format_tools_for_prompt(self) -> str:\n",
    "        \"\"\"Format all available tools into a format the language model can understand.\"\"\"\n",
    "        tools_json = []\n",
    "        for tool in self.tools.values():\n",
    "            try:\n",
    "                # Use the specification provided by the @tool decorator\n",
    "                tools_json.append(json.loads(tool.specification))\n",
    "            except (json.JSONDecodeError, AttributeError):\n",
    "                # Fallback for tools without proper specification\n",
    "                tools_json.append({\n",
    "                    \"name\": tool.name,\n",
    "                    \"description\": getattr(tool, \"description\", \"No description available\"),\n",
    "                    \"parameters\": {\"properties\": {}}\n",
    "                })\n",
    "        \n",
    "        print(f\"{Fore.CYAN}Formatted {len(tools_json)} tools for LLM prompt{Style.RESET_ALL}\")\n",
    "        return f\"<tools>\\n{json.dumps(tools_json, indent=2)}\\n</tools>\"\n",
    "    \n",
    "    def extract_tool_calls(self, response: str) -> List[Dict[str, Any]]:\n",
    "        \"\"\"\n",
    "        Parse the language model's response to extract tool call requests.\n",
    "        \n",
    "        Args:\n",
    "            response: The text response from the language model\n",
    "            \n",
    "        Returns:\n",
    "            A list of tool call dictionaries with 'name' and 'arguments' keys\n",
    "        \"\"\"\n",
    "        tool_calls = []\n",
    "        pattern = r\"<tool_call>(.*?)</tool_call>\"\n",
    "        matches = re.findall(pattern, response, re.DOTALL)\n",
    "        \n",
    "        for match in matches:\n",
    "            try:\n",
    "                tool_call = json.loads(match.strip())\n",
    "                if \"name\" in tool_call and \"arguments\" in tool_call:\n",
    "                    tool_calls.append(tool_call)\n",
    "            except json.JSONDecodeError:\n",
    "                continue\n",
    "        \n",
    "        if tool_calls:\n",
    "            print(f\"{Fore.YELLOW}Extracted {len(tool_calls)} tool call(s) from LLM response{Style.RESET_ALL}\")\n",
    "        else:\n",
    "            print(f\"{Fore.YELLOW}No tool calls found in LLM response{Style.RESET_ALL}\")\n",
    "                \n",
    "        return tool_calls\n",
    "    \n",
    "    def execute_tool(self, tool_call: Dict[str, Any]) -> Any:\n",
    "        \"\"\"\n",
    "        Execute a tool based on the model's request.\n",
    "        \n",
    "        Args:\n",
    "            tool_call: Dictionary with 'name' and 'arguments' for the tool\n",
    "            \n",
    "        Returns:\n",
    "            The result from executing the tool\n",
    "        \"\"\"\n",
    "        tool_name = tool_call.get(\"name\")\n",
    "        arguments = tool_call.get(\"arguments\", {})\n",
    "        \n",
    "        if tool_name not in self.tools:\n",
    "            print(f\"{Fore.RED}Error: Tool '{tool_name}' not found{Style.RESET_ALL}\")\n",
    "            return f\"Error: Tool '{tool_name}' not found\"\n",
    "            \n",
    "        tool = self.tools[tool_name]\n",
    "        print(f\"{Fore.MAGENTA}Executing tool: {tool_name} with arguments: {json.dumps(arguments)}{Style.RESET_ALL}\")\n",
    "        \n",
    "        # Validate and convert argument types using the tool's specification\n",
    "        try:\n",
    "            if hasattr(tool, \"specification\"):\n",
    "                tool_spec = json.loads(tool.specification)\n",
    "                validated_args = self.convert_argument_types(\n",
    "                    {\"arguments\": arguments}, \n",
    "                    tool_spec\n",
    "                )[\"arguments\"]\n",
    "                arguments = validated_args\n",
    "                print(f\"{Fore.BLUE}Arguments validated and converted to appropriate types{Style.RESET_ALL}\")\n",
    "        except (json.JSONDecodeError, AttributeError, KeyError) as e:\n",
    "            print(f\"{Fore.RED}Error validating arguments: {str(e)}{Style.RESET_ALL}\")\n",
    "            # Continue with original arguments if validation fails\n",
    "            pass\n",
    "            \n",
    "        try:\n",
    "            # Handle execution based on the tool interface\n",
    "            # First try the execute method for tools created with the @tool decorator\n",
    "            if hasattr(tool, \"execute\"):\n",
    "                print(f\"{Fore.GREEN}Calling tool.execute() method{Style.RESET_ALL}\")\n",
    "                return tool.execute(**arguments)\n",
    "            # Then try the function attribute which is used by the @tool decorator\n",
    "            elif hasattr(tool, \"function\"):\n",
    "                print(f\"{Fore.GREEN}Calling tool.function() method{Style.RESET_ALL}\")\n",
    "                return tool.function(**arguments)\n",
    "            # Fall back to run method\n",
    "            elif hasattr(tool, \"run\"):\n",
    "                print(f\"{Fore.GREEN}Calling tool.run() method{Style.RESET_ALL}\")\n",
    "                return tool.run(**arguments)\n",
    "            # Last resort: call the tool directly if it's callable\n",
    "            elif callable(tool):\n",
    "                print(f\"{Fore.GREEN}Calling tool directly{Style.RESET_ALL}\")\n",
    "                return tool(**arguments)\n",
    "            else:\n",
    "                print(f\"{Fore.RED}Error: Tool '{tool_name}' is not callable{Style.RESET_ALL}\")\n",
    "                return f\"Error: Tool '{tool_name}' is not callable\"\n",
    "        except Exception as e:\n",
    "            print(f\"{Fore.RED}Error executing {tool_name}: {str(e)}{Style.RESET_ALL}\")\n",
    "            return f\"Error executing {tool_name}: {str(e)}\"\n",
    "    \n",
    "    def convert_argument_types(self, tool_call: Dict[str, Any], tool_spec: Dict[str, Any]) -> Dict[str, Any]:\n",
    "        \"\"\"\n",
    "        Convert arguments to their expected types based on tool specification.\n",
    "        \n",
    "        Args:\n",
    "            tool_call: Dictionary containing arguments to convert\n",
    "            tool_spec: Tool specification with expected types\n",
    "            \n",
    "        Returns:\n",
    "            Updated tool call with properly typed arguments\n",
    "        \"\"\"\n",
    "        if \"parameters\" not in tool_spec or \"properties\" not in tool_spec[\"parameters\"]:\n",
    "            return tool_call\n",
    "            \n",
    "        properties = tool_spec[\"parameters\"][\"properties\"]\n",
    "        \n",
    "        # Standard type converters\n",
    "        type_mapping = {\n",
    "            \"int\": int,\n",
    "            \"str\": str,\n",
    "            \"bool\": bool,\n",
    "            \"float\": float,\n",
    "            \"integer\": int,\n",
    "            \"string\": str,\n",
    "            \"boolean\": bool,\n",
    "            \"number\": float\n",
    "        }\n",
    "        \n",
    "        for arg_name, arg_value in tool_call[\"arguments\"].items():\n",
    "            if arg_name in properties and \"type\" in properties[arg_name]:\n",
    "                expected_type = properties[arg_name][\"type\"]\n",
    "                \n",
    "                if expected_type in type_mapping:\n",
    "                    converter = type_mapping[expected_type]\n",
    "                    try:\n",
    "                        # Only convert if types don't match\n",
    "                        if not isinstance(arg_value, converter):\n",
    "                            print(f\"{Fore.BLUE}Converting argument '{arg_name}' from {type(arg_value).__name__} to {expected_type}{Style.RESET_ALL}\")\n",
    "                            tool_call[\"arguments\"][arg_name] = converter(arg_value)\n",
    "                    except (ValueError, TypeError) as e:\n",
    "                        print(f\"{Fore.RED}Type conversion error for '{arg_name}': {str(e)}{Style.RESET_ALL}\")\n",
    "                        # Keep original value if conversion fails\n",
    "                        pass\n",
    "                        \n",
    "        return tool_call\n",
    "    \n",
    "    def run(self, user_input: str) -> str:\n",
    "        print(f\"{Fore.WHITE}{Style.BRIGHT}=== Starting agent run with user input: '{user_input}' ==={Style.RESET_ALL}\")\n",
    "        # Add user input to conversation history\n",
    "        self.conversation_history.append({\"role\": \"user\", \"content\": user_input})\n",
    "\n",
    "        # Build the messages list for OpenAI API\n",
    "        messages = [\n",
    "            {\"role\": \"system\", \"content\": self.system_prompt + \"\\n\\n\" + self.format_tools_for_prompt()}\n",
    "        ]\n",
    "        \n",
    "        # Add conversation history\n",
    "        for message in self.conversation_history:\n",
    "            messages.append({\"role\": message[\"role\"], \"content\": message[\"content\"]})\n",
    "\n",
    "        # Get response from language model\n",
    "        print(f\"{Fore.CYAN}Calling language model...{Style.RESET_ALL}\")\n",
    "        response = self.model(model=\"gpt-4o\", messages=messages)\n",
    "        model_response = response.choices[0].message.content\n",
    "        print(f\"{Fore.CYAN}Received response from language model ({len(model_response)} chars){Style.RESET_ALL}\")\n",
    "\n",
    "        # Extract tool calls from response\n",
    "        tool_calls = self.extract_tool_calls(model_response)\n",
    "        \n",
    "        # If no tool calls, return the response directly\n",
    "        if not tool_calls:\n",
    "            print(f\"{Fore.GREEN}No tool calls needed. Returning response.{Style.RESET_ALL}\")\n",
    "            final_response = model_response\n",
    "        else:\n",
    "            # Execute tools and collect results\n",
    "            tool_results = []\n",
    "            for i, tool_call in enumerate(tool_calls):\n",
    "                print(f\"{Fore.MAGENTA}{Style.BRIGHT}Executing tool call {i+1}/{len(tool_calls)}{Style.RESET_ALL}\")\n",
    "                result = self.execute_tool(tool_call)\n",
    "                tool_results.append({\n",
    "                    \"tool\": tool_call.get(\"name\"),\n",
    "                    \"arguments\": tool_call.get(\"arguments\"),\n",
    "                    \"result\": result\n",
    "                })\n",
    "            \n",
    "            # Format tool results\n",
    "            results_text = \"Tool results:\\n\"\n",
    "            for res in tool_results:\n",
    "                result_str = str(res[\"result\"])\n",
    "                if isinstance(res[\"result\"], (dict, list)):\n",
    "                    try:\n",
    "                        result_str = json.dumps(res[\"result\"], indent=2)\n",
    "                    except:\n",
    "                        pass\n",
    "                    \n",
    "                results_text += f\"- {res['tool']}{json.dumps(res['arguments'])}: {result_str}\\n\"\n",
    "            \n",
    "            print(f\"{Fore.BLUE}Formatted tool results{Style.RESET_ALL}\")\n",
    "            \n",
    "            # Create a new message with original response and tool results\n",
    "            messages.append({\"role\": \"assistant\", \"content\": model_response})\n",
    "            messages.append({\"role\": \"user\", \"content\": results_text})\n",
    "            \n",
    "            # Get final response from language model with tool results\n",
    "            print(f\"{Fore.CYAN}Calling language model with tool results...{Style.RESET_ALL}\")\n",
    "            final_response_obj = self.model(model=\"gpt-4o\", messages=messages)\n",
    "            final_response = final_response_obj.choices[0].message.content\n",
    "            print(f\"{Fore.CYAN}Received final response from language model ({len(final_response)} chars){Style.RESET_ALL}\")\n",
    "        \n",
    "        # Add final response to conversation history\n",
    "        self.conversation_history.append({\n",
    "            \"role\": \"assistant\", \n",
    "            \"content\": final_response\n",
    "        })\n",
    "        \n",
    "        print(f\"{Fore.WHITE}{Style.BRIGHT}=== Agent run completed ===={Style.RESET_ALL}\")\n",
    "        return final_response\n",
    "        \n",
    "    def reset_conversation(self):\n",
    "        \"\"\"Clear the conversation history.\"\"\"\n",
    "        print(f\"{Fore.GREEN}Conversation history reset{Style.RESET_ALL}\")\n",
    "        self.conversation_history = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "116f7ad5",
   "metadata": {},
   "outputs": [],
   "source": [
    "REACT_SYSTEM_PROMPT = \"\"\"\n",
    "# ReAct Agent: Reasoning → Acting Framework  (FIRST-TURN VERSION)\n",
    "\n",
    "You are an AI assistant that solves problems in a strict loop:\n",
    "**Thought → Action → (STOP and wait)**  \n",
    "Only after the system supplies an <observation> may you think again.\n",
    "\n",
    "--------------------------------------------------------------------\n",
    "## How You Operate - first turn\n",
    "\n",
    "1. **THOUGHT** - explain your reasoning and decide which tool to call.  \n",
    "2. **ACTION** - emit exactly one <tool_call> block in valid JSON.  \n",
    "3. **STOP** - output nothing after </tool_call>.  \n",
    "   *Do NOT produce <observation> or <response> until the host returns an observation.*\n",
    "\n",
    "--------------------------------------------------------------------\n",
    "## Available Tools\n",
    "\n",
    "You can invoke any of the functions listed below:\n",
    "\n",
    "<tools>\n",
    "__TOOLS__\n",
    "</tools>\n",
    "\n",
    "--------------------------------------------------------------------\n",
    "## Tool-Calling Format  (follow precisely)\n",
    "\n",
    "<tool_call>{\"name\": \"function_name\", \"arguments\": {\"param1\": value1, \"param2\": value2}}</tool_call>\n",
    "\n",
    "*Example - if one tool is*  \n",
    "{\"name\":\"compute_sum\",\"parameters\":{\"properties\":{\"a\":{\"type\":\"int\"},\"b\":{\"type\":\"int\"}}}}\n",
    "\n",
    "→ valid call:  \n",
    "<tool_call>{\"name\":\"compute_sum\",\"arguments\":{\"a\":10,\"b\":20}}</tool_call>\n",
    "\n",
    "--------------------------------------------------------------------\n",
    "## First-Turn Template you MUST follow\n",
    "\n",
    "<thought>…your reasoning here…</thought>  \n",
    "<tool_call>{\"name\":\"<one-of-the-tool-names>\",\"arguments\":{…}}</tool_call>\n",
    "\n",
    "*(Nothing after </tool_call>.)*\n",
    "\n",
    "--------------------------------------------------------------------\n",
    "## What happens next\n",
    "\n",
    "- The system executes the call and sends you:  \n",
    "  <observation>{…tool result…}</observation>\n",
    "- You will then start the next cycle (Thought → …).  \n",
    "- When fully certain, finish with:  \n",
    "  <thought>I now know the final answer.</thought>  \n",
    "  <response>…answer…</response>\n",
    "\n",
    "--------------------------------------------------------------------\n",
    "## Important Guidelines\n",
    "\n",
    "- Always begin with a <thought> tag.  \n",
    "- One tool per action; multiple tools → multiple cycles.  \n",
    "- JSON must match the schema exactly (types, key names).  \n",
    "- If no tool is required, state why and answer directly:  \n",
    "\n",
    "  <thought>This question can be answered directly…</thought>  \n",
    "  <response>…answer…</response>\n",
    "\n",
    "- **Never** output <response> in the first turn if you used a tool.  \n",
    "- **Never** add text after your <tool_call>; simply stop.\n",
    "\n",
    "--------------------------------------------------------------------\n",
    "## Context\n",
    "    you dont have memory, so this is your scratchpad. based on it to take your next decision.\n",
    "\n",
    "    __SCRATCHPAD__\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "02842961",
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [\n",
    "    {\n",
    "        \"name\": \"calculate_area\",\n",
    "        \"description\": \"Calculate the area of a rectangle\",\n",
    "        \"parameters\": {\n",
    "            \"properties\": {\n",
    "                \"length\": {\"type\": \"float\"},\n",
    "                \"width\": {\"type\": \"float\"}\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"get_current_weather\",\n",
    "        \"description\": \"Get the current weather for a location\",\n",
    "        \"parameters\": {\n",
    "            \"properties\": {\n",
    "                \"location\": {\"type\": \"string\"},\n",
    "                \"unit\": {\"type\": \"string\"}\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "]\n",
    "\n",
    "# Convert tools to JSON string\n",
    "tools_json = json.dumps(tools, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "fb0b880b",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def add_two_numbers(a: int, b: int) -> int:\n",
    "    \"\"\"Used to add two numbers together\"\"\"\n",
    "    return a + b\n",
    "\n",
    "@tool\n",
    "def calculate_area_of_rectangle(length: float, width: float) -> float:\n",
    "    \n",
    "    \"\"\"Used to calculate the area of a rectangle\"\"\"\n",
    "    return length * width"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "cbf34c9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"name\": \"add_two_numbers\", \"description\": \"Used to add two numbers together\", \"parameters\": {\"properties\": {\"a\": {\"type\": \"int\"}, \"b\": {\"type\": \"int\"}}}}'"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "add_two_numbers.specification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "4d030798",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"name\": \"add_two_numbers\", \"description\": \"Used to add two numbers together\", \"parameters\": {\"properties\": {\"a\": {\"type\": \"int\"}, \"b\": {\"type\": \"int\"}}}}{\"name\": \"calculate_area_of_rectangle\", \"description\": \"Used to calculate the area of a rectangle\", \"parameters\": {\"properties\": {\"length\": {\"type\": \"float\"}, \"width\": {\"type\": \"float\"}}}}\n"
     ]
    }
   ],
   "source": [
    "tools = [add_two_numbers, calculate_area_of_rectangle]\n",
    "tools_mapping = {tool.name: tool for tool in tools}\n",
    "\n",
    "tools_specifications = \"\".join([tool.specification for tool in tools])\n",
    "\n",
    "\n",
    "print(tools_specifications)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "07c3de96",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import google.generativeai as genai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "734a9df6",
   "metadata": {},
   "outputs": [],
   "source": [
    "genai.configure(api_key=os.environ[\"GOOGLE_API_KEY\"])\n",
    "        \n",
    "llm = genai.GenerativeModel(\n",
    "  model_name=\"gemini-1.5-flash\",\n",
    "  generation_config={\"temperature\": 0}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "ebb4138e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_response_to_dict(response_content: str) -> dict:\n",
    "    \"\"\"\n",
    "    Extracts all <tool_call> JSON blocks from the response_content and returns them as a list of dicts.\n",
    "    Handles errors gracefully.\n",
    "    \"\"\"\n",
    "    import re\n",
    "    import json\n",
    "\n",
    "    tool_calls = []\n",
    "    try:\n",
    "        # Find all <tool_call>...</tool_call> blocks\n",
    "        matches = re.findall(r\"<tool_call>\\s*(\\{.*?\\})\\s*</tool_call>\", response_content, re.DOTALL)\n",
    "        if not matches:\n",
    "            raise ValueError(\"No <tool_call> JSON found in response.\")\n",
    "\n",
    "        for match in matches:\n",
    "            try:\n",
    "                tool_calls.append(json.loads(match))\n",
    "            except json.JSONDecodeError as e:\n",
    "                tool_calls.append({\n",
    "                    \"name\": \"JSONDecodeError\",\n",
    "                    \"message\": f\"Error decoding JSON: {str(e)}\",\n",
    "                    \"raw\": match\n",
    "                })\n",
    "        return tool_calls\n",
    "    except Exception as e:\n",
    "        return [{\n",
    "            \"name\": type(e).__name__,\n",
    "            \"message\": str(e),\n",
    "            \"stack\": None\n",
    "        }]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "53277a7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tool_result(transformed_response):\n",
    "  for tool_call in transformed_response:\n",
    "    tool_name = tool_call.get(\"name\")\n",
    "    tool = tools_mapping.get(tool_name)\n",
    "    if tool:\n",
    "      return tool.execute(**tool_call.get(\"arguments\", {}))\n",
    "    else:\n",
    "      raise(f\"Tool {tool_name} not found in tools_mapping\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "d09b3971",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<question>The sum of 10 and 20 is the width of a rectangle that is 100 units long. What is the area of the rectangle?<\\question>\n",
      "<thought>The problem requires two steps. First, I need to add 10 and 20 using the `add_two_numbers` tool.  Then, I'll use the result as the width in the `calculate_area_of_rectangle` tool to compute the area.</thought>\n",
      "<tool_call>{\"name\": \"add_two_numbers\", \"arguments\": {\"a\": 10, \"b\": 20}}</tool_call>\n",
      "<observation>30</observation>\n",
      "\n",
      "<question>The sum of 10 and 20 is the width of a rectangle that is 100 units long. What is the area of the rectangle?<\\question>\n",
      "<thought>The problem requires two steps. First, I need to add 10 and 20 using the `add_two_numbers` tool.  Then, I'll use the result as the width in the `calculate_area_of_rectangle` tool to compute the area.</thought>\n",
      "<tool_call>{\"name\": \"add_two_numbers\", \"arguments\": {\"a\": 10, \"b\": 20}}</tool_call>\n",
      "<observation>30</observation>\n",
      "<thought>The `add_two_numbers` tool returned 30.  Now I will use this as the width and the given length of 100 in the `calculate_area_of_rectangle` tool.</thought>\n",
      "<tool_call>{\"name\": \"calculate_area_of_rectangle\", \"arguments\": {\"length\": 100, \"width\": 30}}</tool_call>\n",
      "<observation>3000</observation>\n",
      "\n",
      "<question>The sum of 10 and 20 is the width of a rectangle that is 100 units long. What is the area of the rectangle?<\\question>\n",
      "<thought>The problem requires two steps. First, I need to add 10 and 20 using the `add_two_numbers` tool.  Then, I'll use the result as the width in the `calculate_area_of_rectangle` tool to compute the area.</thought>\n",
      "<tool_call>{\"name\": \"add_two_numbers\", \"arguments\": {\"a\": 10, \"b\": 20}}</tool_call>\n",
      "<observation>30</observation>\n",
      "<thought>The `add_two_numbers` tool returned 30.  Now I will use this as the width and the given length of 100 in the `calculate_area_of_rectangle` tool.</thought>\n",
      "<tool_call>{\"name\": \"calculate_area_of_rectangle\", \"arguments\": {\"length\": 100, \"width\": 30}}</tool_call>\n",
      "<observation>3000</observation>\n",
      "<thought>The `calculate_area_of_rectangle` tool returned 3000. This is the area of the rectangle.</thought>\n",
      "<response>3000</response>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def run(prompt):\n",
    "  scratchpad = f\"<question>{prompt}<\\question>\"\n",
    "  while True:\n",
    "    PROMPT = REACT_SYSTEM_PROMPT.replace(\"__TOOLS__\", tools_specifications).replace(\"__SCRATCHPAD__\", scratchpad)\n",
    "    output = llm.generate_content(PROMPT).text\n",
    "    scratchpad = scratchpad + \"\\n\" + output\n",
    "    if \"<response>\" not in output:\n",
    "      transformed_response = transform_response_to_dict(output)\n",
    "      r = tool_result(transformed_response)\n",
    "      scratchpad = scratchpad + f\"<observation>{r}</observation>\"\n",
    "    else:\n",
    "      print(scratchpad)\n",
    "      return\n",
    "    print(scratchpad+'\\n')\n",
    "\n",
    "run(\"The sum of 10 and 20 is the width of a rectangle that is 100 units long. What is the area of the rectangle?\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "570f68ea",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
